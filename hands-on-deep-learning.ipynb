{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hands-on - Deep Learning para Reconhecimento de Padrões em Imagem\n### Detecção de Derrame Pleural em Rx de Tórax\n\nDensenvolvido por: Eduardo Pontes Reis e Felipe Nascimento","metadata":{"id":"Kbcoog8wUeBF","_uuid":"5f8b8216cd5b021c380bc802582bdd519cd6e3c2"}},{"cell_type":"markdown","source":"**REFERÊNCIAS:**\n\nSão utilizadas imagens selecionadas do dataset público NIH ChestXray14.\n\nParte do material didático foi baseado no tutorial \n[https://github.com/llSourcell/Convolutional_neural_network](https://github.com/llSourcell/Convolutional_neural_network)\ne parte do código foi baseado no workshop realizado na JPR2018, entre outros códigos de caráter open source.\n\n","metadata":{"id":"Wr8HCqgi_ysX","_uuid":"5160142c64539896ac3ca0387d2de46f718726fb"}},{"cell_type":"markdown","source":"**OBJETIVO:**\n\nDemonstrar os passos básicos para treinamento de rede neural convolucional para detectar derrame pleural.\n","metadata":{"id":"R7EnOa6MUeBG","_uuid":"b2687b08a6bc1db492473c6c8c3b7da5393e4f10"}},{"cell_type":"markdown","source":"**RECURSOS:**\n\nO notebook do Kaggle é um computador em nuvem rodando um ambiente python contendo todas as configurações necessárias para machine learning.\n\nTodo o processo é realizado em linguagem Python, utilizando bibliotecas como Keras/Tensorflow, Numpy, openCV, SKlearn, entre outras.\n\nAs bibliotecas específicas para cada tarefa são importadas ao longo do processo.","metadata":{"id":"fIt6E6YWUeBH","_uuid":"9d24e88661262a90d9f8c4583491804879ffafcd"}},{"cell_type":"markdown","source":"# Introdução à Rede Neural Convolucional (CNN)\n\nAs CNN são modelos inspirados na biologia do córtex visual dos mamíferos. Hubel e Wiesel (1960) propuseram explicação para a forma com que os mamíferos percebem visualmente o mundo ao seu redor utilizando arquitetura em camadas de neurônios no cérebro, e isso, por sua vez, inspirou os engenheiros a desenvolver mecanismos semelhantes de reconhecimento de padrões na visão computacional. A figura abaixo, inspirada por DiCarlo e Cox (2007), ilustra as transformações que ocorrem no fluxo visual ventral.\n\n![alt text](https://github.com/EPreis/handsonfigs/blob/master/visualcortex2.jpg?raw=true)\n\n\nNa hipótese dos autores citados, dentro do córtex visual, respostas funcionais complexas geradas por células \"profundas\" são construídas a partir de respostas simples de \"élulas iniciais\". Por exemplo, células simples responderão a linhas especificamente orientadas e bordas, enquanto células profundas também responderão a certas orientações, mas com grau progressivo de complexidade.\n\nBasicamente uma célula profunda responde a soma de entradas de outras células iniciais. A arquitetura das redes neurais convolucionais foi inspirada nestas idéias.\n\n\n\n","metadata":{"id":"10tUyEau1XhX","_uuid":"98ba3aa13cfd15495c2f4c652bd46f3a63632767"}},{"cell_type":"markdown","source":"# Iniciando o Processo\n# Passo 1: Criando o dataset\n\n**Dataset:**\n\n    O NIH ChestXray14 contém cerca de 110.000 exames de raio x de tórax anotados em 14 diferentes categorias.\n\nO conjunto de dados que é utilizado consiste de 350 imagens de RX de tórax normais e 350 RX com derrame, retiradas e selecionadas do dataset público NIH ChestXray14.\n\n\n** Siga as instruções em texto e em azul dentro das células. **\n#### Para executar cada célula, pressione SHIFT + ENTER","metadata":{"id":"u-qAsa1iUeBH","_uuid":"a3e52f61b51cad3b4ad10f78477d85357dc86347"}},{"cell_type":"code","source":"# As imagens do Dataset \"RxTorax\" que contém 350 imagens normais e 350 de derrame já estão vinculadas a este \"Notebook\"\n# Para editar o dataset vinculado a este kernel vá em \"Add Data\" no menu à direita. \n# Agora que ja temos o dataset pronto, vamos criar uma lista dos arquivos utilizando o glob, que lê e lista os arquivos que existem dentro de uma pasta\n\nfrom glob import glob\n\nderrame_dir = '../input/effusion/*/*.png' #Define o caminho das pastas que contém as imagens\nnormal_dir = '../input/normal/*/*.png'\n\nderrame_lista = glob(derrame_dir) #Lista os arquivos dentro de cada uma das pastas, usando o glob()\nnormal_lista = glob(normal_dir)\n\n\nprint('Número de casos com derrame: ', len(derrame_lista)) #Visualiza o tamanho da lista\nprint('Número de casos normais: ', len(normal_lista))\nprint ('\\nEtapa Concluída. Vamos para a próxima!')\n\n#Execute com SHIFT + ENTER\n\n#O resultado esperado é:\n#Número de casos com derrame:  350\n#Número de casos normais:  350","metadata":{"id":"jHMr3gvuUeBL","outputId":"4c1ddfed-b491-4eed-cd07-ecb30cff160a","_uuid":"f293b08b9519c4bcd4d7f2d599255bb8eecbfb1e","execution":{"iopub.status.busy":"2022-08-07T22:35:00.721081Z","iopub.execute_input":"2022-08-07T22:35:00.721378Z","iopub.status.idle":"2022-08-07T22:35:01.046373Z","shell.execute_reply.started":"2022-08-07T22:35:00.721335Z","shell.execute_reply":"2022-08-07T22:35:01.045798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizando seus dados\n\nPode-se também visualizar cada imagem do dataset. Por exemplo, para visualizar uma imagem com derrame: na linha \"ID_arquivo\" escolha um numero entre 0 e 349 e execute a célula, pode-se repetir o quanto necessário.","metadata":{"id":"Mrbc2giZf1fX","_uuid":"40de0d7eeac138d17545b0ada95ebafe19e18349"}},{"cell_type":"code","source":"import cv2 #Para abrir o arquivo de imagem, utilizaremos o openCV, uma biblioteca aberta de visão computacional\nfrom matplotlib import pyplot as plt #Biblioteca de plotagem de gráficos chamada a matplotlib\n\n#Em 'Classe' digite 'N' para imagens da classe 'Normal', \n#ou substitua-o por 'D' para imagens com derrame\nClasse = 'D'\n\n#Escolha uma imagem entre 0 e 349:\nID_arquivo = 102\n\nif Classe == 'N':\n    classe = 'Normal'\n    classe_lista = normal_lista\nelif Classe == 'D':\n    classe = 'Derrame'\n    classe_lista = derrame_lista\n    \nimagem = cv2.imread(classe_lista[ID_arquivo])\n\nplt.imshow(imagem)\nplt.show()\n    \nprint('Classe: ',classe)\nprint ('\\nEtapa Concluída. Vamos para a próxima!')\n\n#Execute com SHIFT + ENTER\n#Pode modificar o ID_arquivo ou a Classe para vizualizar outras imagens. Pode repetir quantas vezes quiser","metadata":{"id":"YPRYbFl3UeBR","outputId":"a95d7a7d-670f-463a-bdd3-e6ef59797e96","_uuid":"ce8e5c8613df1f2206f320e4e2366697b553e605","execution":{"iopub.status.busy":"2022-08-07T22:35:01.047609Z","iopub.execute_input":"2022-08-07T22:35:01.047915Z","iopub.status.idle":"2022-08-07T22:35:01.444060Z","shell.execute_reply.started":"2022-08-07T22:35:01.047881Z","shell.execute_reply":"2022-08-07T22:35:01.443250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Como o computador enxerga uma imagem?**\n\nConsidere cada imagem como uma matriz em que o valor de cada pixel corresponde a um \nnúmero que determina o tom de cinza da imagem.\n\n![alt text](https://github.com/EPreis/handsonfigs/blob/master/8_digits.gif?raw=true)\n\n\nPortanto, para enxergar os contornos de uma imagem o algoritmo tenta criar filtros que representem estes contornos em números, como no exemplo abaixo.\n\n![alt text](https://github.com/EPreis/handsonfigs/blob/master/contornos.png?raw=true)\n\n\n","metadata":{"id":"ZmllICZr8h_m","_uuid":"6668cb7fec9e54b07b15042418b5f11fd1ef9029"}},{"cell_type":"markdown","source":"# Passo 2: Criando os Labels e transformando as imagens em matrizes (números)\n\nÉ necessário informar explicitamente em qual categoria as imagens pertecem em uma lista denominada labels (derrame = 1, normal = 0). Isso será realizado ao mesmo tempo que as imagens são salvas em uma matriz, pois como as redes neurais tem entrada de tamanho fixo, é necessário redimensionar todas as imagens para tamanho único que deve ser exatamente o mesmo da primeira camada da rede neural convolucional (Input Layer) utilizada. Imagine que cada pixel será transformado em um número que será inserido em cada neurônio da primeira camada, para este caso será utilizado tamanho de 256 x 256 pixels.","metadata":{"id":"dLxxkb7klevm","_uuid":"cb6aeaf780c23e7f55872f128d2fcc533a9e312d"}},{"cell_type":"code","source":"import numpy as np #biblioteca NumPy para trabalharmos com matrizes\n# Por que usamos matrizes? A entrada de informações nas redes neurais se dá nesse formato,\n# o computador enxerga as imagens dessa forma e permite processamento computacional paralelo e maior velocidade de processamento.\n\ndataset = [] # cria uma lista vazia para incluir as imagens do dataset\nlabels = [] # cria uma lista vazia para incluir a categoria a qual cada imagem pertence (0 ou 1)\n\nfor arquivo in derrame_lista: # para cada arquivo de imagem na lista derrame:\n    img = cv2.imread(arquivo, cv2.IMREAD_GRAYSCALE) #abre o arquivo em escala de cinzas\n    img = cv2.resize(img, (256,256)) #redimensiona a imagem para 256 x 256\n    dataset.append(img) #adiciona essa imagem na lista do dataset que criamos acima\n    labels.append(1) #informa que ela é um caso de derrrame (1)\n\n#Agora faremos o mesmo para as imagens sem derrame\nfor arquivo in normal_lista:\n    img = cv2.imread(arquivo, cv2.IMREAD_GRAYSCALE) \n    img = cv2.resize(img, (256,256)) \n    dataset.append(img)\n    labels.append(0) #mas agora informaremos que ela é um caso normal (0)\n\n    \n\ndataset = np.asarray(dataset, dtype=np.float32) #transforma a lista de variáveis numa matriz\nlabels = np.asarray(labels)\n\nfor i in range(len(dataset)):\n  dataset[i] = (dataset[i] - np.average(dataset[i], axis= (0, 1))) / np.std(dataset[i], axis= (0, 1)) #faremos a normalização, dividindo a média pelo desvio padrão\n  # normalização diminui a variabilizada do dataset, deixando os valores mais próximos um do outro\n  \nprint('Dimensões da Matriz: ',dataset.shape)\nprint ('\\nEtapa Concluída. Vamos para a próxima!')\n\n#Vamos ver qual o tamanho dessa matriz 'dataset'\n#Esperamos que a primeira dimensão dela seja de 700 (350 casos de derrame e 350 normais)\n#A segunda e a terceira dimensões devem ser 256.\n\n# a saída esperada é (700, 256, 256)","metadata":{"id":"Nwjuot4_UeBT","outputId":"7074e00f-ca64-4d3c-bc74-97b348f5ddf7","_uuid":"5a067425c7612e4e5a25a9804fabc02fca4b38b8","execution":{"iopub.status.busy":"2022-08-07T22:35:01.445416Z","iopub.execute_input":"2022-08-07T22:35:01.445641Z","iopub.status.idle":"2022-08-07T22:35:12.471673Z","shell.execute_reply.started":"2022-08-07T22:35:01.445602Z","shell.execute_reply":"2022-08-07T22:35:12.470820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Passo 3: Dividindo o dataset nos grupos Treinamento, Validação e Teste\n\n![alt text](https://github.com/edureisMD/handsonfigs/blob/master/Captura.png?raw=true)","metadata":{"id":"iC4uu87DUeBZ","_uuid":"1c28eb34a8fa1c0856d625d51f99d757d9f034ae"}},{"cell_type":"code","source":"#Vamos separar nosso dataset em grupos de treinamento, validação e teste. Para isso, usaremos a biblioteca sklearn.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\n#Vamos dividir o grupo de treino, validação e teste na proporção de cerca de 70%/15%/15%, \n#com valores aproximados para ficarmos com números redondos de 500/100/100\n\ndataset_train, dataset_test, labels_train, labels_test = train_test_split(dataset[:,...,np.newaxis], labels[:,...,np.newaxis], test_size=0.142, random_state=80)\ndataset_train, dataset_val, labels_train, labels_val = train_test_split(dataset_train, labels_train, test_size=0.1651, random_state=80)\n\nprint('(Número de imagens, Imagem_X, Imagem_Y, canais de cor) (Número de labels, 1)')\nprint(dataset_train.shape, labels_train.shape)\nprint(dataset_val.shape, labels_val.shape)\nprint(dataset_test.shape, labels_test.shape)\n\n#Você deve ver a seguinte saída:\n#(500, 256, 256, 1) (500,1)\n#(100, 256, 256, 1) (100,1)\n#(100, 256, 256, 1) (100,1)\n\nprint ('\\nEtapa Concluída. Vamos para a próxima!')","metadata":{"id":"gTnE2xwHUeBa","outputId":"e4f9adf3-801b-43c3-f183-af24af59268c","_uuid":"3c42d1f324a385d467f73cb3d6712ff3769e62bd","execution":{"iopub.status.busy":"2022-08-07T22:35:12.473283Z","iopub.execute_input":"2022-08-07T22:35:12.473607Z","iopub.status.idle":"2022-08-07T22:35:13.060613Z","shell.execute_reply.started":"2022-08-07T22:35:12.473550Z","shell.execute_reply":"2022-08-07T22:35:13.059844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Passo 4: Processo de Data Augmentation\n\nO dataset utilizado é considerado pequeno, o que eleva a possibilidade de overfiting do modelo, ou seja, o modelo se torna especialista em apenas os RX de tórax apresentados, não conseguindo generalizar para variados RX de tórax do mundo real, com posições diferentes, coloração, entre outros.\n\nPara aumentar artificialmente o número de exemplos, será utilizada técnica denominada Data Augmentation, que atua levemente na posição da imagem de forma aleatória, antes mesmo de apresentá-las para a rede neural. \n\n![alt text](https://github.com/EPreis/handsonfigs/blob/master/aug.002.jpeg?raw=true)","metadata":{"id":"RLEXPet6qtPq","_uuid":"038b6eeaa1479b1fdcf8c0f3a132f28868ecf37b"}},{"cell_type":"code","source":"#Vamos importar as função do Keras que faz data augmentation:\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#Aqui podemos definir diferentes variáveis que vão definir como as imagens  \n#vão mudar em rotação, \"corte\" ou zoom.\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nprint ('\\nEtapa Concluída. Vamos para a próxima!')","metadata":{"id":"4Ymx_7LTJMv-","outputId":"f46277de-8c79-4250-94b2-1cce7b3da46d","_uuid":"c9ccb5615c26914bf127d10c620805dcd1d838a6","execution":{"iopub.status.busy":"2022-08-07T22:35:13.063758Z","iopub.execute_input":"2022-08-07T22:35:13.064092Z","iopub.status.idle":"2022-08-07T22:35:13.075272Z","shell.execute_reply.started":"2022-08-07T22:35:13.064041Z","shell.execute_reply":"2022-08-07T22:35:13.074211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Passo 5: Criando a estrutura da rede neural convolucional","metadata":{"id":"PA2NK3_HUeBV","_uuid":"1a2e837e31f43cc61ba781f217defdb7fc3e19b0"}},{"cell_type":"markdown","source":"Convolução é uma operação matemática que consiste em multiplicar uma matriz (imagem) por um filtro (matrix de pesos).\n\n\n\n---\n\n\n\n\nLembra-se de como o computador enxerga um contorno?\nAtravés de uma matriz de números estratégicamente orientados:\n\n\n![alt text](https://github.com/EPreis/handsonfigs/blob/master/Screen-Shot-2017-07-26-at-6.13.41-PM.png?raw=true)\n\n---\n\n\n\nSerão utilizados os filtros núméricos para enxergar os contornos ao longo de toda a imagem.\n\n![alt text](https://media3.giphy.com/media/i4NjAwytgIRDW/giphy.gif?cid=ecf05e47xxytwe09f1mjua95h5exicu1gouki8wgenmql6sy&rid=giphy.gif)\n\n\n\nEsta operação é repetida várias vezes para que a rede enxergue características cada vez mais complexas, gerando filtros decontornos assim como representado na famosa imagem da Lena.\n\n![alt text](https://github.com/EPreis/handsonfigs/blob/master/contornos.png?raw=true)","metadata":{"id":"u2R8IIKOUeBW","_uuid":"d0f35278ed0f12af618aed1b0add3da3e4c9abe5"}},{"cell_type":"code","source":"#Nesta etapa vamos criar a arquitetura da nossa rede neural convolucional, \n#Utilizaremos a biblioteca Keras, própria para Deep Learning em Python\n#Inicialmente vamos importar as funções do Keras que iremos utilizar:\n\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras.layers.core import Dense, Dropout\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPool2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.layers import Input, Concatenate, add\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import Activation, Dense, LeakyReLU\nfrom keras.utils.np_utils import to_categorical\nimport keras\n\n#Agora criaremos a estrutura da rede neural convolucional\n\n#A primeira camada define o tamanho da camada de entrada da rede\nimgs = Input(shape=(256,256,1))\n\n#Lembre que a nossa matriz com todas as 556 imagens de cada categoria tem o formato (556, 256, 256)\n#Nesse caso a entrada (input) da rede é cada imagem individualmente\n#Ou seja, uma imagem de tamanho 256 x 256 pixels e 1 canal de cor (escala de cinzas) (256, 256, 1)\n\n#Agora vamos adicionar a primeira camada convolucional\nx = Conv2D(8, 3, padding='same', activation='relu')(imgs)\n\n#Em seguida, adicionamos uma camada MaxPool, que irá reduzir em 75% o tamanho da saída da camada convolucional.\n#Fazemos isso para evitar que o número de parâmetros da rede aumente demais.\nx = MaxPool2D()(x)\n\n#Adicionaremos mais camadas convolucionais, seguidas de MaxPool\nx = Conv2D(8, 3, padding='same', activation='relu')(x)\nx = MaxPool2D()(x)\nx = Conv2D(12, 3, padding='same', activation='relu')(x)\nx = MaxPool2D()(x)\nx = Conv2D(12, 3, padding='same', activation='relu')(x)\nx = MaxPool2D()(x)\nx = Conv2D(20, 5, padding='same', activation='relu')(x)\nx = MaxPool2D()(x)\nx = Conv2D(20, 5, padding='same', activation='relu')(x)\nx = MaxPool2D()(x)\nx = Conv2D(50, 5, padding='same', activation='relu')(x)\nx = GlobalAveragePooling2D()(x)\n\n#Finalmente adicionaremos duas camadas densas, chamadas de 'Fully Connected Layers'.\n#Essas camadas são redes neurais não convolucionais.\n#Estas camadas recebem os parâmetros das primeiras e ajudam a realizar a classificação dos resultados\nx = Dense(128, activation='relu')(x)\n\n#Dropout é uma técnica para reduzir overfitting onde excluímos parte dos neurônios de uma camada.\nx = Dropout(0.6)(x)\n\nx = Dense(32, activation='relu')(x)\n\n#Nossa camada de \"output\" tem o argumento \"1\" pois a saída da rede é a classificação derrame x não-derrame\n#Ou seja, a saída da rede é apenas um número (0 ou 1)\noutputs = Dense(1, activation='sigmoid')(x)\n\ninputs = imgs\n\n#Por fim, definiremos nossa rede com a entrada e a saída da rede\nRadEinstein_CNN = Model(inputs=inputs, outputs=outputs)\n\n#Agora, definiremos o método de otimização da rede: ADAM, com a taxa de aprendizado e de decaimento\n#Cada um desses parâmetros é ajustável.\ncustom_adam = optimizers.Adam(lr=0.0005, decay=0.0002)\n\n#Compila o modelo definindo o tipo de função 'loss', otimização e a métrica.\nRadEinstein_CNN.compile(loss='binary_crossentropy', optimizer=custom_adam, metrics=['acc'])\n\nprint('Veja abaixo as camadas da sua rede neural' )\nprint('Note que cada camada contém uma quantidade diferente de parâmetros a serem treinados')\nprint('No final da lista, note que nossa rede contém um total de 54.627 parâmetros treináveis')\nprint ('\\nRadEinstein_CNN Sumary')\nRadEinstein_CNN.summary()\nprint ('\\nEtapa Concluída. Vá para a próxima!')","metadata":{"id":"jU-OirSmvIRZ","outputId":"6dc72045-90bf-419a-8796-d9e91a127327","_uuid":"cefbbb6eda1c59fcd4404a1cef58569b1ab53a44","execution":{"iopub.status.busy":"2022-08-07T22:35:13.076516Z","iopub.execute_input":"2022-08-07T22:35:13.076733Z","iopub.status.idle":"2022-08-07T22:35:13.360419Z","shell.execute_reply.started":"2022-08-07T22:35:13.076691Z","shell.execute_reply":"2022-08-07T22:35:13.359684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Passo 5: Treinando a rede neural\n\nDurante o treinamento da rede, os pesos sinápticos de todas as camadas são atualizados. Após a conclusão do treinamento, cada filtro representará uma característica de imagem a ser procurada nas imagens do nosso dataset. \n\nNa linha \"hist\" são definimos alguns hyperparameters, como por exemplo o número de épocas em 60, que significa por quantas repetições (épocas) é realizado o treinamento. Para treinar ainda mais a sua rede, altere o número para até 100 épocas, e analise os resultados.\n\nCom estes parâmetros, o modelo levará entre 5 e 10 minutos para ser treinado.","metadata":{"id":"ML6EuUk_UeBd","_uuid":"511623def5b4a47fe80e86599221e3d9c80d8ee6"}},{"cell_type":"code","source":"import time #Função time para medirmos o tempo de treinamento\n\ncheckpointer = ModelCheckpoint(filepath='Melhor_modelo.hdf5', monitor='val_loss',\n                               verbose=1, save_best_only=True) #Salvar o melhor modelo que for encontrado durante o treino\n\nprint('Treinando a Rede RadEinstein_CNN:')\n\nValida = (dataset_val, labels_val)\n\n# Finalmente vamos treinar a nossa rede\n# Se quiser treinar sua rede um pouco mais, altere o número de epochs, \n# e vamos ver os diferentes resultados.\n\nstart_time = time.time()\nhist = RadEinstein_CNN.fit_generator(datagen.flow(dataset_train, labels_train, batch_size=16), \n                                     steps_per_epoch=len(dataset_train), \n                                     epochs=100, \n                                     validation_data= (dataset_val, labels_val), \n                                     callbacks=[checkpointer])\n\n#Definimos o treinamento com o dataset de treino, realizando validação no dataset de validação.\n#O treinamento não usa o dataset de teste, ficará guardado para avaliarmos nossa rede depois.\n\ntempo = str(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\nprint('')\nprint('Treino finalizado em %s' % tempo)\n\n#Por fim, plotamos os resultados de evolução da medida de erro (loss) e acurácia ao longo dos epochs\nplt.plot(hist.history['loss'], 'b-', label='train loss')\nplt.plot(hist.history['val_loss'], 'r-', label='val loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()\n\nplt.plot(hist.history['acc'], 'b-', label='train accuracy')\nplt.plot(hist.history['val_acc'], 'r-', label='val accuracy')\nplt.ylabel('acc')\nplt.xlabel('epoch')\nplt.show()\n\nprint ('\\nAgora vamos avaliar o modelo no dataset de teste. Vamos para a próximo comando.')\n\n#Execute esse código com SHIFT + ENTER","metadata":{"id":"UsOO98YmUeBf","outputId":"d09ec490-db48-46af-8b59-787619a0824f","_uuid":"7759dfd779ef0e8f73809dd61a10859315e213a3","execution":{"iopub.status.busy":"2022-08-07T22:35:13.362745Z","iopub.execute_input":"2022-08-07T22:35:13.363534Z","iopub.status.idle":"2022-08-08T02:15:56.797309Z","shell.execute_reply.started":"2022-08-07T22:35:13.363486Z","shell.execute_reply":"2022-08-08T02:15:56.796499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nA menor diferença entre o que o algoritmo prediz e a resposta correta, esta diferença é chamada de perda (loss), quanto menor a perda (loss), mais o seu algoritmo esta acertando, consequentemente maior é a acurácia (acc).\n\n![alt text](https://i1.wp.com/francescolelli.info/wp-content/uploads/2019/05/NeuralNetworks-input-layer-hidden-layer-output-layer.png?resize=448%2C293&ssl=1)\nFonte: https://francescolelli.info/tutorial/neural-networks-a-collection-of-youtube-videos-for-learning-the-basics/\n\n\nO gráfico abaixo ilustra o processo de otimização para o treinamento da rede neural, buscando o ponto de menor perda (loss) (em cor azul escuro). O processo de otimização pode percorrer vários caminhos diferentes de forma heurística ou determinística, por isso é necessário repetir o processo várias vezes, até o algoritmo de otimização atingir um mínimo local ou o mínimo global. O algoritmo de otimização é de extrema importância no processo de treinamento das redes neurais, pois em cada caso específico pode-se utilizar tipos diferentes de otimizador buscando assim atingir melhorar a acurácia no modelo.\n\n![alt text](https://regenerativetoday.com/wp-content/uploads/2019/06/GradientDescentWithMutlipleLocalMinimum.jpg)\nFonte: https://regenerativetoday.com/machine-learning-gradient-descent-concept/\n\n","metadata":{"id":"49rx6p7nCN6D","_uuid":"1d286a019df7bcef18e902f411349e760718ed6a"}},{"cell_type":"markdown","source":"# Passo 6: Avaliação do algoritmo no dataset de Teste\n\nNesta estapa, será apresentado todo o dataset de teste para o modelo desenvolvido, de forma a calcular a acurácia da rede neural em um grupo de imagens que o modelo desconhece.","metadata":{"id":"dWTfJB-dUeBi","_uuid":"62bac077b9b6fa2d27dc7312e293a393d4b7d52a"}},{"cell_type":"code","source":"from keras.models import load_model #Vamos importar a função do keras que abre modelos salvos previamente\n\nmelhor_modelo = load_model('Melhor_modelo.hdf5') #Abrimos o melhor modelo que salvamos no treinamento\n\nprint ('\\nPesos da rede neural atualizados para os da melhor época.')\nprint ('\\nEtapa Concluída. Vamos para a próxima!')\n#Execute esse código com SHIFT + ENTER","metadata":{"id":"xykHvjiaUeBl","outputId":"34f595b7-1e88-400c-bbd0-2ef13988a502","_uuid":"4247c6ac8ad2403099b52b3e45e939b32acec5bc","execution":{"iopub.status.busy":"2022-08-08T02:15:56.798858Z","iopub.execute_input":"2022-08-08T02:15:56.799200Z","iopub.status.idle":"2022-08-08T02:15:59.163603Z","shell.execute_reply.started":"2022-08-08T02:15:56.799142Z","shell.execute_reply":"2022-08-08T02:15:59.162290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Usamos a função evaluate para avaliar a acurácia do nosso modelo no grupo de teste\nprint('Acurácia no grupo de teste: ', melhor_modelo.evaluate(dataset_test, labels_test, verbose=0)[1])\n\nprint ('\\033[1m' + 'Etapa Concluída. Vamos para a próxima!')\n#Execute esse código com SHIFT + ENTER","metadata":{"id":"D-N8kbE1UeBn","outputId":"d468b63d-18f2-4376-bb1c-1f7c793e0816","_uuid":"5e25b5a3cece7953f026d0c0bc9836de0167a87b","execution":{"iopub.status.busy":"2022-08-08T02:15:59.164786Z","iopub.execute_input":"2022-08-08T02:15:59.165055Z","iopub.status.idle":"2022-08-08T02:16:00.058312Z","shell.execute_reply.started":"2022-08-08T02:15:59.165002Z","shell.execute_reply":"2022-08-08T02:16:00.057182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## # Passo 7: Verificação da predição caso a caso","metadata":{"id":"v9gffU3IUeBp","_uuid":"53ac231ac36c538a32f895a756d1ca264a208bb8"}},{"cell_type":"code","source":"# Instale a biblioteca Keras-vis para visualizarmos como a rede neural enxerga a imagem.\n# Se tiver problemas com a instalação ative o campo \"internet\" na barra lateral de configurações -->\n!pip install -q keras-vis\nprint ('\\033[1m' + 'Instalação concluída. Vamos para a próxima etapa!')\n","metadata":{"execution":{"iopub.status.busy":"2022-08-08T02:16:00.059583Z","iopub.execute_input":"2022-08-08T02:16:00.059906Z","iopub.status.idle":"2022-08-08T02:16:05.901338Z","shell.execute_reply.started":"2022-08-08T02:16:00.059853Z","shell.execute_reply":"2022-08-08T02:16:05.900221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Agora vamos visualizar as predições para algumas imagens\n# e visualizar o mapa de ativação no nosso dataset de teste.\n\n# Fonte: https://fairyonice.github.io/Grad-CAM-with-keras-vis.html\n\nfrom vis.visualization import visualize_cam\nimport matplotlib.cm as cm\nimport random \n\ndef plot_map(grads, classe, predicao):\n    fig, axes = plt.subplots(1,2,figsize=(14,5))\n    axes[0].imshow(np.squeeze(img), cmap='gray')\n    axes[1].imshow(np.squeeze(img), cmap='gray')\n    i = axes[1].imshow(grads,cmap=\"jet\",alpha=0.5)\n    fig.colorbar(i)\n    plt.suptitle(\"Classe: {}. Pred = {}\".format(classe, predicao))\n    \nfor n in range(10):\n    i = random.randrange(0,100)\n    ID_imagem = i\n    \n    img = dataset_test[ID_imagem]\n    layer_idx = 18\n    penultimate_layer_idx = 13\n    class_idx  = 0\n    seed_input = img\n    grad_top1  = visualize_cam(melhor_modelo, layer_idx, class_idx, seed_input, \n                               penultimate_layer_idx = penultimate_layer_idx,#None,\n                               backprop_modifier     = None,\n                               grad_modifier         = None)\n    \n    #Vamos mostrar a qual classe ela pertence\n    _classe = 'normal' if labels_test[ID_imagem]==0 else 'derrame'\n\n    _predicao = melhor_modelo.predict(dataset_test[ID_imagem][np.newaxis,:,...], verbose=0)\n\n    plot_map(grad_top1, _classe, _predicao[0][0])","metadata":{"execution":{"iopub.status.busy":"2022-08-08T02:16:05.903519Z","iopub.execute_input":"2022-08-08T02:16:05.903922Z","iopub.status.idle":"2022-08-08T02:16:14.762981Z","shell.execute_reply.started":"2022-08-08T02:16:05.903854Z","shell.execute_reply":"2022-08-08T02:16:14.761936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## # Passo 8: Execução da última célula para concluir o treinamento:","metadata":{}},{"cell_type":"code","source":"from IPython.display import HTML, display\nprint ('\\n' + '\\033[1m' + 'Ótimo trabalho! Parabéns, você treinou sua primeira rede neural!\\n')\ndisplay(HTML('<img src=\"https://media0.giphy.com/media/S6TEoUBJuGfQCoGl8l/giphy.gif?cid=ecf05e47oxgcxjd98g6ghdaalezi4jhrkxmig00jf8vhg2np&rid=giphy.gif\">'))\n","metadata":{"execution":{"iopub.status.busy":"2022-08-08T02:16:14.764885Z","iopub.execute_input":"2022-08-08T02:16:14.765276Z","iopub.status.idle":"2022-08-08T02:16:14.772954Z","shell.execute_reply.started":"2022-08-08T02:16:14.765214Z","shell.execute_reply":"2022-08-08T02:16:14.772093Z"},"trusted":true},"execution_count":null,"outputs":[]}]}